{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "##    Description    Functions to manage SDFiles, pandas Dataframes ...\n",
    "##                   Applicability Domain analysis\n",
    "##                   \n",
    "##    Authors:       Kevin Pinto Gil (kevin.pinto@upf.edu)\n",
    "##                   Manuel Pastor (manuel.pastor@upf.edu)\n",
    "##\n",
    "##    Copyright 2018 Manuel Pastor\n",
    "##\n",
    "##    This file is part of PhiTools\n",
    "##\n",
    "##    PhiTools is free software: you can redistribute it and/or modify\n",
    "##    it under the terms of the GNU General Public License as published by\n",
    "##    the Free Software Foundation version 3.\n",
    "##\n",
    "##    PhiTools is distributed in the hope that it will be useful,\n",
    "##    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "##    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "##    GNU General Public License for more details.\n",
    "##\n",
    "##    You should have received a copy of the GNU General Public License\n",
    "##    along with PhiTools.  If not, see <http://www.gnu.org/licenses/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Could not find EPA module. Will use only the CACTVS web service to resolve CAS number structures. ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### General libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import * #math commands will be available every time you start an interactive session\n",
    "\n",
    "## Dataframe visualization part\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.max_rows = 4000\n",
    "\n",
    "## Ignore Warnings \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Checking Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDuplicatesDF(df, colname):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    Info\n",
    "    ----\n",
    "    This function checks if there is any duplicate molecules by colname (e.g. InChI key).\n",
    "    It is highly recommended to checked this using as a colname the Standard and non Standard InChI key.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df: inditexDF       \n",
    "        ## Pandas Dataframe \n",
    "    colname: 'inchikey' \n",
    "        ## Molecule column to be used to check duplicates\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    duplist: Duplicated molecule names list\n",
    "    dupDF:   Dataframe containing duplicated molecules\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    \n",
    "    duplist, dupDF = getDuplicatesDF(inditexDF, 'inchikey')\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    AttributeError: The ``Raises`` section is a list of all exceptions\n",
    "        that are relevant to the interface.\n",
    "    ValueError: IF dataframe is empty.\n",
    "            \n",
    "    '''    \n",
    "    \n",
    "#     df['phiID'] = [str('mol%0.6d'%(int(x)+1)) for x in range(len(df))]\n",
    "\n",
    "    if not df.empty:\n",
    "    \n",
    "        duplist = df[df[colname].duplicated()][colname]\n",
    "#         print ('\\033[1m' +'1. Duplicates checking section:'+'\\033[0m')\n",
    "        print ('\\nOriginal DF molecules = '+ str(len(df)))\n",
    "        print ('\\nThe number of '+colname+' duplicates in are  = '+ str(duplist.count()))\n",
    "        print ('\\nThe '+ colname + 'duplicates list is: \\n'+str(np.array(duplist)))\n",
    "\n",
    "        ## This dataframe contains duplicated molecules with metal ion decoupled\n",
    "        dupDF = df[df[colname].isin(duplist)]\n",
    "#         dupDF = dupDF.sort_values(by=[colname, 'phiID'], ascending=[True, True])\n",
    "        return (duplist, dupDF)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('The Dataframe is empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dropping Dupplicates (keeping different info in list) and curate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropDupMols(df, colname, molcol= None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Info\n",
    "    ----\n",
    "    \n",
    "    After standardising molecules, one needs to check duplicates with getDuplicateDF\n",
    "    function. After knowing how many duplicates you have, one should keep 1 molecule but\n",
    "    keep the whole information of the other duplicate molecules. \n",
    "    This function allows one to obtain a dataframe where the duplicated molecule contains\n",
    "    the information in a list in every column separated by comma. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df:  stdDF\n",
    "        ## obtained after standardising, but also after checking Excluded molecules\n",
    "    colname: 'parent_inkey' \n",
    "        ## colname to groupby\n",
    "    molcol: 'MolProt'\n",
    "        ## By default is None, if there is molecule column defined, we will keep the first one. \n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Dataframe with NO duplicates.\n",
    "    Cells where non unique value was found, the value will be joined separated by ', ',\n",
    "    such as \"ROCHE_PC_RO0052807, AZ_GGA_200002374\"\n",
    "    \n",
    "    Example\n",
    "    -------        \n",
    "    \n",
    "    etoxNoDupDF = dropDupMols(stdDF,'parent_inkey')\n",
    "         \n",
    "    '''\n",
    "   \n",
    "    if not df.empty:\n",
    "#         df1 = df.groupby([colname]).aggregate(lambda x : set(x))\n",
    "#         cols = df.columns.drop(colname)\n",
    "#         df1.reset_index(level=0, inplace=True)\n",
    "#         df1[cols] = df1[cols].applymap(list)\n",
    "        if molcol != None:\n",
    "            ### Molecule Part\n",
    "            df1 = df[[colname, molcol]].groupby([colname]).aggregate(lambda x : set(x))\n",
    "            df1[molcol] = df1[molcol].apply(list)\n",
    "            df1[molcol] = [x[0] for x in df1[molcol]]\n",
    "            \n",
    "            ### Rest of dataframe part\n",
    "            cols = df.columns.drop(molcol)\n",
    "            df2 = df[cols].groupby([colname]).aggregate(lambda x : \", \".join(map(str, set(x))))\n",
    "            df1.reset_index(level=0, inplace=True)\n",
    "            df2.reset_index(level=0, inplace=True)\n",
    "            \n",
    "            ### Joining molecule and rest of dataframe\n",
    "            df3 = pd.merge(df2, df1 , left_on=colname, right_on=colname, how='inner')\n",
    "            return(df3)\n",
    "    \n",
    "        else:\n",
    "#             df1 = df.groupby([colname]).aggregate(lambda x : \", \".join(map(repr, set(x))))\n",
    "            df1 = df.groupby([colname]).aggregate(lambda x : \", \".join(map(str, set(x))))\n",
    "            df1.reset_index(level=0, inplace=True)\n",
    "            return (df1)\n",
    "            \n",
    "#         return (df1)\n",
    "        \n",
    "    else:\n",
    "        print('Dataframe is empty')\n",
    "        df1 = pd.DataFrame([])\n",
    "        return (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curateCol(dfname, colname, t):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    Info\n",
    "    ----\n",
    "    \n",
    "    This function allows one to curate columns from dataframe after using \n",
    "    my dropDupMols function. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    dfname: df   \n",
    "        ### dataframe name\n",
    "    \n",
    "    colname: 'molecular_weight'\n",
    "        ### column name to be curated\n",
    "    \n",
    "    t: float, str or int\n",
    "        ### you need to choose between float or int or str\n",
    "        ### str: it's going to keep the first item and erase the other ones\n",
    "        ### int: convert string to integer and calcule the mean value. If any nan value, eliminate them.\n",
    "        ### float: convert string to float and calcule the mean value. If any nan value, eliminate them.\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Dataframe with curated columns.\n",
    "    \n",
    "    Example\n",
    "    -------        \n",
    "    \n",
    "    curatedDF = curate(dropdupDF, 'std_smiles', str)\n",
    "         \n",
    "    '''\n",
    "    \n",
    "    df = dfname.copy()\n",
    "    if t == float:\n",
    "#         print ('I am a fucking float')\n",
    "        for x, y in zip(df[colname], df.index):\n",
    "            if ', ' in x:\n",
    "                x = np.array(x.split(', ')).astype(np.float)\n",
    "                if True in np.isnan(x):\n",
    "                    x = x[~np.isnan(x)] \n",
    "                    if len(x) == 0:\n",
    "                        x = nan\n",
    "                        df.loc[df.index.isin([y]), colname] = x\n",
    "                        \n",
    "                    else:\n",
    "                        x = np.mean(x)\n",
    "                        df.loc[df.index.isin([y]), colname] = x\n",
    "                        continue\n",
    "                else:\n",
    "                    x = np.mean(x)\n",
    "                    df.loc[df.index.isin([y]), colname] = x\n",
    "    elif t == int:\n",
    "#         print ('I am a fucking int')\n",
    "        for x, y in zip(df[colname], df.index):\n",
    "            if ', ' in x:\n",
    "                x = np.array(x.split(', ')).astype(np.int)\n",
    "                if True in np.isnan(x):\n",
    "                    x = x[~np.isnan(x)] \n",
    "                    if len(x) == 0:\n",
    "                        x = nan\n",
    "                        df.loc[df.index.isin([y]), colname] = x   \n",
    "                    else:\n",
    "                        x = np.mean(x)\n",
    "                        df.loc[df.index.isin([y]), colname] = x\n",
    "                        continue\n",
    "                else:\n",
    "                    x = np.mean(x)\n",
    "                    df.loc[df.index.isin([y]), colname] = x\n",
    "    elif t == str:\n",
    "#         print ('This is only used for compounds with same stdinkey and different smile')\n",
    "        for x, y in zip(df[colname], df.index):\n",
    "            if ', ' in x:\n",
    "                x = np.array(x.split(', '))\n",
    "#                 print ( x, 'is changed for ' , x[0], 'with an index of ', y)\n",
    "                x = x[0]\n",
    "                df.loc[df.index.isin([y]), colname] = x\n",
    "            else:\n",
    "                df.loc[df.index.isin([y]), colname] = x\n",
    "                continue\n",
    "\n",
    "#     elif t == 'mol':\n",
    "# #         print ('This is only used for compounds with same stdinkey and different smile')\n",
    "#         for x, y in zip(df[colname], df.index):\n",
    "#             if ', ' in x:\n",
    "#                 x = np.array(x.split(', '))\n",
    "#                 x = x[0]\n",
    "#                 df.loc[df.index.isin([y]), colname] = x\n",
    "#             else:\n",
    "#                 df.loc[df.index.isin([y]), colname] = x\n",
    "#                 continue\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dropping rows giving a list \n",
    "- e.g. in parent_inkey column drop a row that contains pinkeylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropRowsbycolumnlist(df, cn, cl):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Info\n",
    "    ----\n",
    "\n",
    "    This functions allows one to drop rows by column list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df: DF  \n",
    "        ## Dataframe containing all information\n",
    "    cn: colName \n",
    "        ## Column name to check molecules to drop\n",
    "    cl: mollist \n",
    "        ## List of molecules present in column to be dropped \n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Dataframe with cl ('molecule list') removed from original dataframe.\n",
    "    \n",
    "    Example\n",
    "    -------        \n",
    "\n",
    "    df = DF\n",
    "    cn = 'parent_inkey'\n",
    "    cl = ['INFDPOAKFNIJBF-UHFFFAOYSA-N', 'SYJFEGQWDCRVNX-UHFFFAOYSA-N',\n",
    "          'CTSLUCNDVMMDHG-UHFFFAOYSA-N', 'ZFSLODLOARCGLH-UHFFFAOYSA-N']\n",
    "    DF = dropRowsbycolumnlist(df, cn, cl)\n",
    "\n",
    "         \n",
    "    '''\n",
    "\n",
    "    x = df[~df[cn].isin(cl)]\n",
    "    print (len(x))\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
